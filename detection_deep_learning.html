<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>参考文献表</title>
</head>
<body>
<div class="csl-bib-body" style="line-height: 1.35; ">
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[1]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">X. Tong, S. Peng, B. Tian, Y. Guo, X. Huang, and Z. Ma, “Improving Transformer Based Line Segment Detection with Matched Predicting and Re-ranking.” 2025. [Online]. Available: <a href="https://arxiv.org/abs/2502.17766">https://arxiv.org/abs/2502.17766</a></div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=document&amp;rft.title=Improving%20Transformer%20Based%20Line%20Segment%20Detection%20with%20Matched%20Predicting%20and%20Re-ranking&amp;rft.identifier=https%3A%2F%2Farxiv.org%2Fabs%2F2502.17766&amp;rft.aufirst=Xin&amp;rft.aulast=Tong&amp;rft.au=Xin%20Tong&amp;rft.au=Shi%20Peng&amp;rft.au=Baojie%20Tian&amp;rft.au=Yufei%20Guo&amp;rft.au=Xuhui%20Huang&amp;rft.au=Zhe%20Ma&amp;rft.date=2025"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[2]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">X. Ma, Y. Liu, W. Zhou, R. Wang, and H. Huang, “Generating 3D House Wireframes with Semantics,” in <i>Computer Vision – ECCV 2024</i>, A. Leonardis, E. Ricci, S. Roth, O. Russakovsky, T. Sattler, and G. Varol, Eds., Cham: Springer Nature Switzerland, 2025, pp. 223–240.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A978-3-031-72670-5&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Generating%203D%20House%20Wireframes%20with%20Semantics&amp;rft.btitle=Computer%20Vision%20%E2%80%93%20ECCV%202024&amp;rft.place=Cham&amp;rft.publisher=Springer%20Nature%20Switzerland&amp;rft.aufirst=Xueqi&amp;rft.aulast=Ma&amp;rft.au=Xueqi%20Ma&amp;rft.au=Yilin%20Liu&amp;rft.au=Wenjun%20Zhou&amp;rft.au=Ruowei%20Wang&amp;rft.au=Hui%20Huang&amp;rft.au=Ale%C5%A1%20Leonardis&amp;rft.au=Elisa%20Ricci&amp;rft.au=Stefan%20Roth&amp;rft.au=Olga%20Russakovsky&amp;rft.au=Torsten%20Sattler&amp;rft.au=G%C3%BCl%20Varol&amp;rft.date=2025&amp;rft.pages=223%E2%80%93240&amp;rft.spage=223&amp;rft.epage=240&amp;rft.isbn=978-3-031-72670-5&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[3]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">J. Zhang, J. Yang, F. Fu, and J. Ma, “Structural asymmetric convolution for wireframe parsing,” <i>Engineering Applications of Artificial Intelligence</i>, vol. 128, p. 107410, 2024, doi: <a href="https://doi.org/10.1016/j.engappai.2023.107410">https://doi.org/10.1016/j.engappai.2023.107410</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2Fhttps%3A%2F%2Fdoi.org%2F10.1016%2Fj.engappai.2023.107410&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Structural%20asymmetric%20convolution%20for%20wireframe%20parsing&amp;rft.jtitle=Engineering%20Applications%20of%20Artificial%20Intelligence&amp;rft.volume=128&amp;rft.aufirst=Jiahui&amp;rft.aulast=Zhang&amp;rft.au=Jiahui%20Zhang&amp;rft.au=Jinfu%20Yang&amp;rft.au=Fuji%20Fu&amp;rft.au=Jiaqi%20Ma&amp;rft.date=2024&amp;rft.pages=107410"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[4]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">J. Zhang, J. Yang, F. Fu, and J. Ma, “Multi-scale Structural Asymmetric Convolution for Wireframe Parsing,” in <i>Neural Information Processing</i>, Singapore: Springer Nature Singapore, 2024, pp. 239–251.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Multi-scale%20Structural%20Asymmetric%20Convolution%20for%20Wireframe%20Parsing&amp;rft.btitle=Neural%20Information%20Processing&amp;rft.place=Singapore&amp;rft.publisher=Springer%20Nature%20Singapore&amp;rft.aufirst=Jiahui&amp;rft.aulast=Zhang&amp;rft.au=Jiahui%20Zhang&amp;rft.au=Jinfu%20Yang&amp;rft.au=Fuji%20Fu&amp;rft.au=Jiaqi%20Ma&amp;rft.date=2024&amp;rft.pages=239%E2%80%93251&amp;rft.spage=239&amp;rft.epage=251"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[5]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">H. Yu, H. Li, W. Yang, L. Yu, and G.-S. Xia, “Detecting Line Segments in Motion-Blurred Images With Events,” <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 46, no. 5, pp. 2866–2881, 2024, doi: <a href="https://doi.org/10.1109/TPAMI.2023.3334877">10.1109/TPAMI.2023.3334877</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FTPAMI.2023.3334877&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Detecting%20Line%20Segments%20in%20Motion-Blurred%20Images%20With%20Events&amp;rft.jtitle=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;rft.volume=46&amp;rft.issue=5&amp;rft.aufirst=Huai&amp;rft.aulast=Yu&amp;rft.au=Huai%20Yu&amp;rft.au=Hao%20Li&amp;rft.au=Wen%20Yang&amp;rft.au=Lei%20Yu&amp;rft.au=Gui-Song%20Xia&amp;rft.date=2024&amp;rft.pages=2866-2881&amp;rft.spage=2866&amp;rft.epage=2881&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[6]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">J. Yang <i>et al.</i>, “MLNet: An multi-scale line detector and descriptor network for 3D reconstruction,” <i>Knowledge-Based Systems</i>, vol. 289, p. 111476, 2024, doi: <a href="https://doi.org/10.1016/j.knosys.2024.111476">https://doi.org/10.1016/j.knosys.2024.111476</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2Fhttps%3A%2F%2Fdoi.org%2F10.1016%2Fj.knosys.2024.111476&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=MLNet%3A%20An%20multi-scale%20line%20detector%20and%20descriptor%20network%20for%203D%20reconstruction&amp;rft.jtitle=Knowledge-Based%20Systems&amp;rft.volume=289&amp;rft.aufirst=Jian&amp;rft.aulast=Yang&amp;rft.au=Jian%20Yang&amp;rft.au=Yuan%20Rao&amp;rft.au=Qing%20Cai&amp;rft.au=Eric%20Rigall&amp;rft.au=Hao%20Fan&amp;rft.au=Junyu%20Dong&amp;rft.au=Hui%20Yu&amp;rft.date=2024&amp;rft.pages=111476&amp;rft.issn=0950-7051&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[7]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">N. Xue <i>et al.</i>, “NEAT: Distilling 3D Wireframes from Neural Attraction Fields,” in <i>2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2024, pp. 19968–19977. doi: <a href="https://doi.org/10.1109/CVPR52733.2024.01887">10.1109/CVPR52733.2024.01887</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR52733.2024.01887&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=NEAT%3A%20Distilling%203D%20Wireframes%20from%20Neural%20Attraction%20Fields&amp;rft.btitle=2024%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;rft.aufirst=Nan&amp;rft.aulast=Xue&amp;rft.au=Nan%20Xue&amp;rft.au=Bin%20Tan&amp;rft.au=Yuxi%20Xiao&amp;rft.au=Liang%20Dong&amp;rft.au=Gui-Song%20Xia&amp;rft.au=Tianfu%20Wu&amp;rft.au=Yujun%20Shen&amp;rft.date=2024&amp;rft.pages=19968-19977&amp;rft.spage=19968&amp;rft.epage=19977"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[8]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">X. Wang, H. Zhang, H. Yu, and X. Wan, “EvLSD-IED: Event-Based Line Segment Detection With Image-to-Event Distillation,” <i>IEEE Transactions on Instrumentation and Measurement</i>, vol. 73, pp. 1–12, 2024, doi: <a href="https://doi.org/10.1109/TIM.2024.3460882">10.1109/TIM.2024.3460882</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FTIM.2024.3460882&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=EvLSD-IED%3A%20Event-Based%20Line%20Segment%20Detection%20With%20Image-to-Event%20Distillation&amp;rft.jtitle=IEEE%20Transactions%20on%20Instrumentation%20and%20Measurement&amp;rft.volume=73&amp;rft.aufirst=Xinya&amp;rft.aulast=Wang&amp;rft.au=Xinya%20Wang&amp;rft.au=Haitian%20Zhang&amp;rft.au=Huai%20Yu&amp;rft.au=Xianrong%20Wan&amp;rft.date=2024&amp;rft.pages=1-12&amp;rft.spage=1&amp;rft.epage=12&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[9]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Z. Liu, X. Wang, B. Pu, J. Tang, and J. Sun, “WireframePose: Monocular 6-D Pose Estimation of Metal Parts Based on Wireframe Extraction and Matching,” <i>IEEE Transactions on Instrumentation and Measurement</i>, vol. 73, pp. 1–10, 2024, doi: <a href="https://doi.org/10.1109/TIM.2024.3460945">10.1109/TIM.2024.3460945</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FTIM.2024.3460945&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=WireframePose%3A%20Monocular%206-D%20Pose%20Estimation%20of%20Metal%20Parts%20Based%20on%20Wireframe%20Extraction%20and%20Matching&amp;rft.jtitle=IEEE%20Transactions%20on%20Instrumentation%20and%20Measurement&amp;rft.volume=73&amp;rft.aufirst=Ze%E2%80%99An&amp;rft.aulast=Liu&amp;rft.au=Ze%E2%80%99An%20Liu&amp;rft.au=Xuanyin%20Wang&amp;rft.au=Bin%20Pu&amp;rft.au=Jixiang%20Tang&amp;rft.au=Jiaqi%20Sun&amp;rft.date=2024&amp;rft.pages=1-10&amp;rft.spage=1&amp;rft.epage=10&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[10]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">J. Ji, J. Shen, X. Wang, T. Feng, and S. Wu, “WirePAuS: Auxiliary-free Single-shot Wireframe Parsing,” in <i>2024 IEEE International Conference on Multimedia and Expo (ICME)</i>, 2024, pp. 1–6. doi: <a href="https://doi.org/10.1109/ICME57554.2024.10688260">10.1109/ICME57554.2024.10688260</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FICME57554.2024.10688260&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=WirePAuS%3A%20Auxiliary-free%20Single-shot%20Wireframe%20Parsing&amp;rft.btitle=2024%20IEEE%20International%20Conference%20on%20Multimedia%20and%20Expo%20(ICME)&amp;rft.aufirst=Jinkang&amp;rft.aulast=Ji&amp;rft.au=Jinkang%20Ji&amp;rft.au=Junao%20Shen&amp;rft.au=Xinyu%20Wang&amp;rft.au=Tian%20Feng&amp;rft.au=Sensen%20Wu&amp;rft.date=2024&amp;rft.pages=1-6&amp;rft.spage=1&amp;rft.epage=6&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[11]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">S. Janampa and M. Pattichis, “DT-LSD: Deformable Transformer-based Line Segment Detection,” <i>arXiv preprint arXiv:2411.13005</i>, 2024.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=DT-LSD%3A%20Deformable%20Transformer-based%20Line%20Segment%20Detection&amp;rft.jtitle=arXiv%20preprint%20arXiv%3A2411.13005&amp;rft.aufirst=Sebastian&amp;rft.aulast=Janampa&amp;rft.au=Sebastian%20Janampa&amp;rft.au=Marios%20Pattichis&amp;rft.date=2024&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[12]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Z. Guo <i>et al.</i>, “One-Stage Wireframe Parsing in Fish-Eye Images,” in <i>Pattern Recognition and Computer Vision</i>, Q. Liu, H. Wang, Z. Ma, W. Zheng, H. Zha, X. Chen, L. Wang, and R. Ji, Eds., Singapore: Springer Nature Singapore, 2024, pp. 264–275.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A978-981-99-8552-4&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=One-Stage%20Wireframe%20Parsing%20in%20Fish-Eye%20Images&amp;rft.btitle=Pattern%20Recognition%20and%20Computer%20Vision&amp;rft.place=Singapore&amp;rft.publisher=Springer%20Nature%20Singapore&amp;rft.aufirst=Zhengyang&amp;rft.aulast=Guo&amp;rft.au=Zhengyang%20Guo&amp;rft.au=Ruqiang%20Huang&amp;rft.au=Zhongchen%20Shi&amp;rft.au=Wei%20Chen&amp;rft.au=Liang%20Xie&amp;rft.au=Ye%20Yan&amp;rft.au=Erwei%20Yin&amp;rft.au=Qingshan%20Liu&amp;rft.au=Hanzi%20Wang&amp;rft.au=Zhanyu%20Ma&amp;rft.au=Weishi%20Zheng&amp;rft.au=Hongbin%20Zha&amp;rft.au=Xilin%20Chen&amp;rft.au=Liang%20Wang&amp;rft.au=Rongrong%20Ji&amp;rft.date=2024&amp;rft.pages=264%E2%80%93275&amp;rft.spage=264&amp;rft.epage=275&amp;rft.isbn=978-981-99-8552-4&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[13]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">S. Einizinab, K. Khoshelham, S. Winter, and P. Christopher, “Global localization for Mixed Reality visualization using wireframe extraction from images,” <i>ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences</i>, vol. X-4/W5-2024, pp. 119–126, 2024, doi: <a href="https://doi.org/10.5194/isprs-annals-X-4-W5-2024-119-2024">10.5194/isprs-annals-X-4-W5-2024-119-2024</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.5194%2Fisprs-annals-X-4-W5-2024-119-2024&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Global%20localization%20for%20Mixed%20Reality%20visualization%20using%20wireframe%20extraction%20from%20images&amp;rft.jtitle=ISPRS%20Annals%20of%20the%20Photogrammetry%2C%20Remote%20Sensing%20and%20Spatial%20Information%20Sciences&amp;rft.volume=X-4%2FW5-2024&amp;rft.aufirst=S.&amp;rft.aulast=Einizinab&amp;rft.au=S.%20Einizinab&amp;rft.au=K.%20Khoshelham&amp;rft.au=S.%20Winter&amp;rft.au=P.%20Christopher&amp;rft.date=2024&amp;rft.pages=119%E2%80%93126&amp;rft.spage=119&amp;rft.epage=126&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[14]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Y. Zhou <i>et al.</i>, “Semantic Wireframe Detection.” 2023. doi: <a href="https://doi.org/10.24406/publica-2179">10.24406/publica-2179</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=document&amp;rft.title=Semantic%20Wireframe%20Detection&amp;rft.identifier=https%3A%2F%2Fpublica.fraunhofer.de%2Fhandle%2Fpublica%2F457001&amp;rft.aufirst=Yiming&amp;rft.aulast=Zhou&amp;rft.au=Yiming%20Zhou&amp;rft.au=Ahmad%20Osman&amp;rft.au=Marc%20Willms&amp;rft.au=Albrecht%20Kunz&amp;rft.au=Selina%20Philipp&amp;rft.au=Janine%20Blatt&amp;rft.au=Simon%20Eul&amp;rft.date=2023&amp;rft.language=en"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[15]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">N. Xue <i>et al.</i>, “Holistically-Attracted Wireframe Parsing: From Supervised to Self-Supervised Learning,” <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 45, no. 12, pp. 14727–14744, 2023, doi: <a href="https://doi.org/10.1109/TPAMI.2023.3312749">10.1109/TPAMI.2023.3312749</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FTPAMI.2023.3312749&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Holistically-Attracted%20Wireframe%20Parsing%3A%20From%20Supervised%20to%20Self-Supervised%20Learning&amp;rft.jtitle=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;rft.volume=45&amp;rft.issue=12&amp;rft.aufirst=Nan&amp;rft.aulast=Xue&amp;rft.au=Nan%20Xue&amp;rft.au=Tianfu%20Wu&amp;rft.au=Song%20Bai&amp;rft.au=Fu-Dong%20Wang&amp;rft.au=Gui-Song%20Xia&amp;rft.au=Liangpei%20Zhang&amp;rft.au=Philip%20H.%20S.%20Torr&amp;rft.date=2023&amp;rft.pages=14727-14744&amp;rft.spage=14727&amp;rft.epage=14744&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[16]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">D. Gillsjö, G. Flood, and K. Åström, “Semantic Room Wireframe Detection from a Single View,” in <i>2022 26th International Conference on Pattern Recognition (ICPR)</i>, Montreal, QC, Canada, Aug. 2022, pp. 1886–1893. doi: <a href="https://doi.org/10.1109/ICPR56361.2022.9956252">10.1109/ICPR56361.2022.9956252</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FICPR56361.2022.9956252&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Semantic%20Room%20Wireframe%20Detection%20from%20a%20Single%20View&amp;rft.btitle=2022%2026th%20International%20Conference%20on%20Pattern%20Recognition%20(ICPR)&amp;rft.place=Montreal%2C%20QC%2C%20Canada&amp;rft.aufirst=David&amp;rft.aulast=Gillsj%C3%B6&amp;rft.au=David%20Gillsj%C3%B6&amp;rft.au=Gabrielle%20Flood&amp;rft.au=Kalle%20%C3%85str%C3%B6m&amp;rft.date=2022-08&amp;rft.pages=1886-1893&amp;rft.spage=1886&amp;rft.epage=1893&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[17]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">W. Ma, B. Tan, N. Xue, T. Wu, X. Zheng, and G.-S. Xia, “HoW-3D: Holistic 3D Wireframe Perception from a Single Image,” in <i>2022 International Conference on 3D Vision (3DV)</i>, 2022, pp. 596–605. doi: <a href="https://doi.org/10.1109/3DV57658.2022.00070">10.1109/3DV57658.2022.00070</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2F3DV57658.2022.00070&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=HoW-3D%3A%20Holistic%203D%20Wireframe%20Perception%20from%20a%20Single%20Image&amp;rft.btitle=2022%20International%20Conference%20on%203D%20Vision%20(3DV)&amp;rft.aufirst=Wenchao&amp;rft.aulast=Ma&amp;rft.au=Wenchao%20Ma&amp;rft.au=Bin%20Tan&amp;rft.au=Nan%20Xue&amp;rft.au=Tianfu%20Wu&amp;rft.au=Xianwei%20Zheng&amp;rft.au=Gui-Song%20Xia&amp;rft.date=2022&amp;rft.pages=596-605&amp;rft.spage=596&amp;rft.epage=605&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[18]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">N. Kong, K. Park, and H. Goka, “Hole-robust Wireframe Detection,” in <i>2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</i>, 2022, pp. 2684–2693. doi: <a href="https://doi.org/10.1109/WACV51458.2022.00274">10.1109/WACV51458.2022.00274</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FWACV51458.2022.00274&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Hole-robust%20Wireframe%20Detection&amp;rft.btitle=2022%20IEEE%2FCVF%20Winter%20Conference%20on%20Applications%20of%20Computer%20Vision%20(WACV)&amp;rft.aufirst=Naejin&amp;rft.aulast=Kong&amp;rft.au=Naejin%20Kong&amp;rft.au=Kiwoong%20Park&amp;rft.au=Harshith%20Goka&amp;rft.date=2022&amp;rft.pages=2684-2693&amp;rft.spage=2684&amp;rft.epage=2693&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[19]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">J. Huang, X. Lu, M. Yu, and F. Li, “Self-supervised Lightweight Line Segment Detector and Descriptor,” in <i>2022 China Automation Congress (CAC)</i>, 2022, pp. 5263–5268. doi: <a href="https://doi.org/10.1109/CAC57257.2022.10055957">10.1109/CAC57257.2022.10055957</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCAC57257.2022.10055957&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Self-supervised%20Lightweight%20Line%20Segment%20Detector%20and%20Descriptor&amp;rft.btitle=2022%20China%20Automation%20Congress%20(CAC)&amp;rft.aufirst=Jie&amp;rft.aulast=Huang&amp;rft.au=Jie%20Huang&amp;rft.au=Xin%20Lu&amp;rft.au=Mengfan%20Yu&amp;rft.au=Fusheng%20Li&amp;rft.date=2022&amp;rft.pages=5263-5268&amp;rft.spage=5263&amp;rft.epage=5268"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[20]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">H. Zhang, Y. Luo, F. Qin, Y. He, and X. Liu, “ELSD: Efficient Line Segment Detector and Descriptor,” in <i>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</i>, 2021, pp. 2949–2958. doi: <a href="https://doi.org/10.1109/ICCV48922.2021.00296">10.1109/ICCV48922.2021.00296</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FICCV48922.2021.00296&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=ELSD%3A%20Efficient%20Line%20Segment%20Detector%20and%20Descriptor&amp;rft.btitle=2021%20IEEE%2FCVF%20International%20Conference%20on%20Computer%20Vision%20(ICCV)&amp;rft.aufirst=Haotian&amp;rft.aulast=Zhang&amp;rft.au=Haotian%20Zhang&amp;rft.au=Yicheng%20Luo&amp;rft.au=Fangbo%20Qin&amp;rft.au=Yijia%20He&amp;rft.au=Xiao%20Liu&amp;rft.date=2021&amp;rft.pages=2949-2958&amp;rft.spage=2949&amp;rft.epage=2958"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[21]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">N. Xue <i>et al.</i>, “Learning Regional Attraction for Line Segment Detection,” <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 43, no. 6, pp. 1998–2013, 2021, doi: <a href="https://doi.org/10.1109/TPAMI.2019.2958642">10.1109/TPAMI.2019.2958642</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FTPAMI.2019.2958642&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Learning%20Regional%20Attraction%20for%20Line%20Segment%20Detection&amp;rft.jtitle=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;rft.volume=43&amp;rft.issue=6&amp;rft.aufirst=Nan&amp;rft.aulast=Xue&amp;rft.au=Nan%20Xue&amp;rft.au=Song%20Bai&amp;rft.au=Fu-Dong%20Wang&amp;rft.au=Gui-Song%20Xia&amp;rft.au=Tianfu%20Wu&amp;rft.au=Liangpei%20Zhang&amp;rft.au=Philip%20H.S.%20Torr&amp;rft.date=2021&amp;rft.pages=1998-2013&amp;rft.spage=1998&amp;rft.epage=2013"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[22]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Y. Xu, W. Xu, D. Cheung, and Z. Tu, “Line Segment Detection Using Transformers without Edges,” in <i>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2021, pp. 4255–4264. doi: <a href="https://doi.org/10.1109/CVPR46437.2021.00424">10.1109/CVPR46437.2021.00424</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR46437.2021.00424&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Line%20Segment%20Detection%20Using%20Transformers%20without%20Edges&amp;rft.btitle=2021%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;rft.aufirst=Yifan&amp;rft.aulast=Xu&amp;rft.au=Yifan%20Xu&amp;rft.au=Weijian%20Xu&amp;rft.au=David%20Cheung&amp;rft.au=Zhuowen%20Tu&amp;rft.date=2021&amp;rft.pages=4255-4264&amp;rft.spage=4255&amp;rft.epage=4264&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[23]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">C. Qiao, T. Bai, Z. Xiang, Q. Qian, and Y. Bi, “Superline: A Robust Line Segment Feature for Visual SLAM,” in <i>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2021, pp. 5664–5670. doi: <a href="https://doi.org/10.1109/IROS51168.2021.9636435">10.1109/IROS51168.2021.9636435</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FIROS51168.2021.9636435&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Superline%3A%20A%20Robust%20Line%20Segment%20Feature%20for%20Visual%20SLAM&amp;rft.btitle=2021%20IEEE%2FRSJ%20International%20Conference%20on%20Intelligent%20Robots%20and%20Systems%20(IROS)&amp;rft.aufirst=Chengyu&amp;rft.aulast=Qiao&amp;rft.au=Chengyu%20Qiao&amp;rft.au=Tingming%20Bai&amp;rft.au=Zhiyu%20Xiang&amp;rft.au=Qi%20Qian&amp;rft.au=Yunfeng%20Bi&amp;rft.date=2021&amp;rft.pages=5664-5670&amp;rft.spage=5664&amp;rft.epage=5670"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[24]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">R. Pautrat, J.-T. Lin, V. Larsson, M. R. Oswald, and M. Pollefeys, “SOLD<sup>2</sup>: Self-supervised Occlusion-aware Line Description and Detection,” in <i>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2021, pp. 11363–11373. doi: <a href="https://doi.org/10.1109/CVPR46437.2021.01121">10.1109/CVPR46437.2021.01121</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR46437.2021.01121&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=SOLD%3Csup%3E2%3C%2Fsup%3E%3A%20Self-supervised%20Occlusion-aware%20Line%20Description%20and%20Detection&amp;rft.btitle=2021%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;rft.aufirst=R%C3%A9mi&amp;rft.aulast=Pautrat&amp;rft.au=R%C3%A9mi%20Pautrat&amp;rft.au=Juan-Ting%20Lin&amp;rft.au=Viktor%20Larsson&amp;rft.au=Martin%20R.%20Oswald&amp;rft.au=Marc%20Pollefeys&amp;rft.date=2021&amp;rft.pages=11363-11373&amp;rft.spage=11363&amp;rft.epage=11373"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[25]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Q. Ma <i>et al.</i>, “WGLSM: An End-to-End Line Matching Network Based on Graph Convolution,” <i>Neurocomput.</i>, vol. 453, no. C, pp. 195–208, 2021, doi: <a href="https://doi.org/10.1016/j.neucom.2021.04.125">10.1016/j.neucom.2021.04.125</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neucom.2021.04.125&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=WGLSM%3A%20An%20End-to-End%20Line%20Matching%20Network%20Based%20on%20Graph%20Convolution&amp;rft.jtitle=Neurocomput.&amp;rft.volume=453&amp;rft.issue=C&amp;rft.aufirst=Quanmeng&amp;rft.aulast=Ma&amp;rft.au=Quanmeng%20Ma&amp;rft.au=Guang%20Jiang&amp;rft.au=Jiajie%20Wu&amp;rft.au=Changshuai%20Cai&amp;rft.au=Dianzhi%20Lai&amp;rft.au=Zixuan%20Bai&amp;rft.au=Hao%20Chen&amp;rft.date=2021&amp;rft.pages=195%E2%80%93208&amp;rft.spage=195&amp;rft.epage=208&amp;rft.issn=0925-2312"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[26]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">H. Li, H. Yu, J. Wang, W. Yang, L. Yu, and S. Scherer, “ULSD: Unified line segment detection across pinhole, fisheye, and spherical cameras,” <i>ISPRS Journal of Photogrammetry and Remote Sensing</i>, vol. 178, pp. 187–202, 2021, doi: <a href="https://doi.org/10.1016/j.isprsjprs.2021.06.004">https://doi.org/10.1016/j.isprsjprs.2021.06.004</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2Fhttps%3A%2F%2Fdoi.org%2F10.1016%2Fj.isprsjprs.2021.06.004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ULSD%3A%20Unified%20line%20segment%20detection%20across%20pinhole%2C%20fisheye%2C%20and%20spherical%20cameras&amp;rft.jtitle=ISPRS%20Journal%20of%20Photogrammetry%20and%20Remote%20Sensing&amp;rft.volume=178&amp;rft.aufirst=Hao&amp;rft.aulast=Li&amp;rft.au=Hao%20Li&amp;rft.au=Huai%20Yu&amp;rft.au=Jinwang%20Wang&amp;rft.au=Wen%20Yang&amp;rft.au=Lei%20Yu&amp;rft.au=Sebastian%20Scherer&amp;rft.date=2021&amp;rft.pages=187-202&amp;rft.spage=187&amp;rft.epage=202&amp;rft.issn=0924-2716"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[27]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">G. Gu, B. Ko, S. Go, S.-H. Lee, J. Lee, and M. Shin, “Towards Real-time and Light-weight Line Segment Detection.” arXiv, 2021. doi: <a href="https://doi.org/10.48550/ARXIV.2106.00186">10.48550/ARXIV.2106.00186</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=document&amp;rft.title=Towards%20Real-time%20and%20Light-weight%20Line%20Segment%20Detection&amp;rft.rights=arXiv.org%20perpetual%2C%20non-exclusive%20license&amp;rft.publisher=arXiv&amp;rft.identifier=https%3A%2F%2Farxiv.org%2Fabs%2F2106.00186&amp;rft.aufirst=Geonmo&amp;rft.aulast=Gu&amp;rft.au=Geonmo%20Gu&amp;rft.au=Byungsoo%20Ko&amp;rft.au=SeoungHyun%20Go&amp;rft.au=Sung-Hyun%20Lee&amp;rft.au=Jingeun%20Lee&amp;rft.au=Minchul%20Shin&amp;rft.date=2021"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[28]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">X. Dai, X. Yuan, H. Gong, and Y. Ma, “Fully Convolutional Line Parsing.” arXiv, 2021. doi: <a href="https://doi.org/10.48550/ARXIV.2104.11207">10.48550/ARXIV.2104.11207</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=document&amp;rft.title=Fully%20Convolutional%20Line%20Parsing&amp;rft.rights=Creative%20Commons%20Zero%20v1.0%20Universal&amp;rft.publisher=arXiv&amp;rft.identifier=https%3A%2F%2Farxiv.org%2Fabs%2F2104.11207&amp;rft.aufirst=Xili&amp;rft.aulast=Dai&amp;rft.au=Xili%20Dai&amp;rft.au=Xiaojun%20Yuan&amp;rft.au=Haigang%20Gong&amp;rft.au=Yi%20Ma&amp;rft.date=2021&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[29]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">H. Abdellali, R. Frohlich, V. Vilagos, and Z. Kato, “L2D2: Learnable Line Detector and Descriptor,” in <i>2021 International Conference on 3D Vision (3DV)</i>, 2021, pp. 442–452. doi: <a href="https://doi.org/10.1109/3DV53792.2021.00054">10.1109/3DV53792.2021.00054</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2F3DV53792.2021.00054&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=L2D2%3A%20Learnable%20Line%20Detector%20and%20Descriptor&amp;rft.btitle=2021%20International%20Conference%20on%203D%20Vision%20(3DV)&amp;rft.aufirst=Hichem&amp;rft.aulast=Abdellali&amp;rft.au=Hichem%20Abdellali&amp;rft.au=Robert%20Frohlich&amp;rft.au=Viktor%20Vilagos&amp;rft.au=Zoltan%20Kato&amp;rft.date=2021&amp;rft.pages=442-452&amp;rft.spage=442&amp;rft.epage=452"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[30]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">N. Xue <i>et al.</i>, “Holistically-Attracted Wireframe Parsing,” in <i>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2020, pp. 2785–2794. doi: <a href="https://doi.org/10.1109/CVPR42600.2020.00286">10.1109/CVPR42600.2020.00286</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR42600.2020.00286&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Holistically-Attracted%20Wireframe%20Parsing&amp;rft.btitle=2020%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;rft.aufirst=Nan&amp;rft.aulast=Xue&amp;rft.au=Nan%20Xue&amp;rft.au=Tianfu%20Wu&amp;rft.au=Song%20Bai&amp;rft.au=Fudong%20Wang&amp;rft.au=Gui-Song%20Xia&amp;rft.au=Liangpei%20Zhang&amp;rft.au=Philip%20H.S.%20Torr&amp;rft.date=2020&amp;rft.pages=2785-2794&amp;rft.spage=2785&amp;rft.epage=2794&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[31]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Q. Meng, J. Zhang, Q. Hu, X. He, and J. Yu, “LGNN: A Context-Aware Line Segment Detector,” in <i>Proceedings of the 28th ACM International Conference on Multimedia</i>, New York, NY, USA: Association for Computing Machinery, 2020, pp. 4364–4372. [Online]. Available: <a href="https://doi.org/10.1145/3394171.3413784">https://doi.org/10.1145/3394171.3413784</a></div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A978-1-4503-7988-5&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=LGNN%3A%20A%20Context-Aware%20Line%20Segment%20Detector&amp;rft.place=New%20York%2C%20NY%2C%20USA&amp;rft.publisher=Association%20for%20Computing%20Machinery&amp;rft.aufirst=Quan&amp;rft.aulast=Meng&amp;rft.au=Quan%20Meng&amp;rft.au=Jiakai%20Zhang&amp;rft.au=Qiang%20Hu&amp;rft.au=Xuming%20He&amp;rft.au=Jingyi%20Yu&amp;rft.date=2020&amp;rft.pages=4364%E2%80%934372&amp;rft.spage=4364&amp;rft.epage=4372&amp;rft.isbn=978-1-4503-7988-5"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[32]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">S. Huang, F. Qin, P. Xiong, N. Ding, Y. He, and X. Liu, “TP-LSD: Tri-Points Based Line Segment Detector,” in <i>Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXVII</i>, Berlin, Heidelberg: Springer-Verlag, 2020, pp. 770–785. doi: <a href="https://doi.org/10.1007/978-3-030-58583-9_46">10.1007/978-3-030-58583-9_46</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-030-58583-9_46&amp;rft_id=urn%3Aisbn%3A978-3-030-58582-2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=TP-LSD%3A%20Tri-Points%20Based%20Line%20Segment%20Detector&amp;rft.btitle=Computer%20Vision%20%E2%80%93%20ECCV%202020%3A%2016th%20European%20Conference%2C%20Glasgow%2C%20UK%2C%20August%2023%E2%80%9328%2C%202020%2C%20Proceedings%2C%20Part%20XXVII&amp;rft.place=Berlin%2C%20Heidelberg&amp;rft.publisher=Springer-Verlag&amp;rft.aufirst=Siyu&amp;rft.aulast=Huang&amp;rft.au=Siyu%20Huang&amp;rft.au=Fangbo%20Qin&amp;rft.au=Pengfei%20Xiong&amp;rft.au=Ning%20Ding&amp;rft.au=Yijia%20He&amp;rft.au=Xiao%20Liu&amp;rft.date=2020&amp;rft.pages=770%E2%80%93785&amp;rft.spage=770&amp;rft.epage=785&amp;rft.isbn=978-3-030-58582-2"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[33]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Y. Zhou <i>et al.</i>, “Learning to Reconstruct 3D Manhattan Wireframes From a Single Image,” in <i>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</i>, 2019, pp. 7697–7706. doi: <a href="https://doi.org/10.1109/ICCV.2019.00779">10.1109/ICCV.2019.00779</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FICCV.2019.00779&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Learning%20to%20Reconstruct%203D%20Manhattan%20Wireframes%20From%20a%20Single%20Image&amp;rft.btitle=2019%20IEEE%2FCVF%20International%20Conference%20on%20Computer%20Vision%20(ICCV)&amp;rft.aufirst=Yichao&amp;rft.aulast=Zhou&amp;rft.au=Yichao%20Zhou&amp;rft.au=Haozhi%20Qi&amp;rft.au=Yuexiang%20Zhai&amp;rft.au=Qi%20Sun&amp;rft.au=Zhili%20Chen&amp;rft.au=Li-Yi%20Wei&amp;rft.au=Yi%20Ma&amp;rft.date=2019&amp;rft.pages=7697-7706&amp;rft.spage=7697&amp;rft.epage=7706"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[34]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Y. Zhou, H. Qi, and Y. Ma, “End-to-End Wireframe Parsing,” in <i>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</i>, 2019, pp. 962–971. doi: <a href="https://doi.org/10.1109/ICCV.2019.00105">10.1109/ICCV.2019.00105</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FICCV.2019.00105&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=End-to-End%20Wireframe%20Parsing&amp;rft.btitle=2019%20IEEE%2FCVF%20International%20Conference%20on%20Computer%20Vision%20(ICCV)&amp;rft.aufirst=Yichao&amp;rft.aulast=Zhou&amp;rft.au=Yichao%20Zhou&amp;rft.au=Haozhi%20Qi&amp;rft.au=Yi%20Ma&amp;rft.date=2019&amp;rft.pages=962-971&amp;rft.spage=962&amp;rft.epage=971&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[35]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Z. Zhang <i>et al.</i>, “PPGNet: Learning Point-Pair Graph for Line Segment Detection,” in <i>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019, pp. 7098–7107. doi: <a href="https://doi.org/10.1109/CVPR.2019.00727">10.1109/CVPR.2019.00727</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR.2019.00727&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=PPGNet%3A%20Learning%20Point-Pair%20Graph%20for%20Line%20Segment%20Detection&amp;rft.btitle=2019%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;rft.aufirst=Ziheng&amp;rft.aulast=Zhang&amp;rft.au=Ziheng%20Zhang&amp;rft.au=Zhengxin%20Li&amp;rft.au=Ning%20Bi&amp;rft.au=Jia%20Zheng&amp;rft.au=Jinlei%20Wang&amp;rft.au=Kun%20Huang&amp;rft.au=Weixin%20Luo&amp;rft.au=Yanyu%20Xu&amp;rft.au=Shenghua%20Gao&amp;rft.date=2019&amp;rft.pages=7098-7107&amp;rft.spage=7098&amp;rft.epage=7107&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[36]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Z. Xue, N. Xue, G.-S. Xia, and W. Shen, “Learning to Calibrate Straight Lines for Fisheye Image Rectification,” in <i>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019, pp. 1643–1651. doi: <a href="https://doi.org/10.1109/CVPR.2019.00174">10.1109/CVPR.2019.00174</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR.2019.00174&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Learning%20to%20Calibrate%20Straight%20Lines%20for%20Fisheye%20Image%20Rectification&amp;rft.btitle=2019%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;rft.aufirst=Zhucun&amp;rft.aulast=Xue&amp;rft.au=Zhucun%20Xue&amp;rft.au=Nan%20Xue&amp;rft.au=Gui-Song%20Xia&amp;rft.au=Weiming%20Shen&amp;rft.date=2019&amp;rft.pages=1643-1651&amp;rft.spage=1643&amp;rft.epage=1651"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[37]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">N. Xue, S. Bai, F. Wang, G.-S. Xia, T. Wu, and L. Zhang, “Learning Attraction Field Representation for Robust Line Segment Detection,” in <i>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019, pp. 1595–1603. doi: <a href="https://doi.org/10.1109/CVPR.2019.00169">10.1109/CVPR.2019.00169</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR.2019.00169&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Learning%20Attraction%20Field%20Representation%20for%20Robust%20Line%20Segment%20Detection&amp;rft.btitle=2019%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;rft.aufirst=Nan&amp;rft.aulast=Xue&amp;rft.au=Nan%20Xue&amp;rft.au=Song%20Bai&amp;rft.au=Fudong%20Wang&amp;rft.au=Gui-Song%20Xia&amp;rft.au=Tianfu%20Wu&amp;rft.au=Liangpei%20Zhang&amp;rft.date=2019&amp;rft.pages=1595-1603&amp;rft.spage=1595&amp;rft.epage=1603&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[38]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">Y. Sun, X. Han, K. Sun, B. Li, Y. Chen, and M. Li, “Sem-LSD: A Learning-based Semantic Line Segment Detector.” 2019.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=document&amp;rft.title=Sem-LSD%3A%20A%20Learning-based%20Semantic%20Line%20Segment%20Detector&amp;rft.aufirst=Yi&amp;rft.aulast=Sun&amp;rft.au=Yi%20Sun&amp;rft.au=Xushen%20Han&amp;rft.au=Kai%20Sun&amp;rft.au=Boren%20Li&amp;rft.au=Yongjiang%20Chen&amp;rft.au=Mingyang%20Li&amp;rft.date=2019"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[39]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">K. Huang and S. Gao, “Wireframe Parsing With Guidance of Distance Map,” <i>IEEE Access</i>, vol. 7, pp. 141036–141044, 2019, doi: <a href="https://doi.org/10.1109/ACCESS.2019.2943885">10.1109/ACCESS.2019.2943885</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FACCESS.2019.2943885&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Wireframe%20Parsing%20With%20Guidance%20of%20Distance%20Map&amp;rft.jtitle=IEEE%20Access&amp;rft.volume=7&amp;rft.aufirst=Kun&amp;rft.aulast=Huang&amp;rft.au=Kun%20Huang&amp;rft.au=Shenghua%20Gao&amp;rft.date=2019&amp;rft.pages=141036-141044&amp;rft.spage=141036&amp;rft.epage=141044&amp;rft.language=en-US"></span>
  <div class="csl-entry" style="clear: left; ">
    <div class="csl-left-margin" style="float: left; padding-right: 0.5em;text-align: right; width: 2em;">[40]</div><div class="csl-right-inline" style="margin: 0 .4em 0 2.5em;">K. Huang, Y. Wang, Z. Zhou, T. Ding, S. Gao, and Y. Ma, “Learning to Parse Wireframes in Images of Man-Made Environments,” in <i>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, 2018, pp. 626–635. doi: <a href="https://doi.org/10.1109/CVPR.2018.00072">10.1109/CVPR.2018.00072</a>.</div>
  </div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR.2018.00072&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Learning%20to%20Parse%20Wireframes%20in%20Images%20of%20Man-Made%20Environments&amp;rft.btitle=2018%20IEEE%2FCVF%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition&amp;rft.aufirst=Kun&amp;rft.aulast=Huang&amp;rft.au=Kun%20Huang&amp;rft.au=Yifan%20Wang&amp;rft.au=Zihan%20Zhou&amp;rft.au=Tianjiao%20Ding&amp;rft.au=Shenghua%20Gao&amp;rft.au=Yi%20Ma&amp;rft.date=2018&amp;rft.pages=626-635&amp;rft.spage=626&amp;rft.epage=635&amp;rft.language=en-US"></span>
</div></body>
</html>
